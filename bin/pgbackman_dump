#!/usr/bin/env python
#
# Copyright (c) 2013 Rafael Martinez Guerrero (PostgreSQL-es)
# rafael@postgresql.org.es / http://www.postgresql.org.es/
#
# This file is part of PgBck
# https://github.com/rafaelma/pgbck
#
# PgBck is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# PgBck is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with PgBck.  If not, see <http://www.gnu.org/licenses/>.

import subprocess
import tempfile
import datetime
import sys
import os
import time
import signal
import argparse

sys.path.append('/home/rafael/Devel/GIT/pgbackman')

from pgbackman.logs import *
from pgbackman.database import * 
from pgbackman.config import *



# ############################################
# Function 
# ############################################
    
def pg_dump(global_parameters):
    '''pg_dump function'''

    if backup_code == 'FULL':

        print global_parameters['backup_server_pgsql_bin_dir'] + '/pg_dump' + \
            ' -h ' + pgsql_node + \
            ' -p ' + pgsql_node_port + \
            ' -U ' + pgsql_node_admin_user + \
            ' --file=' + global_parameters['database_dump_file'] + \
            ' --format=c' + \
            ' --blobs' + \
            ' ' + extra_parameters + \
            ' ' + dbname + \
            ' > ' + global_parameters['database_log_file'] + ' 2>&1' 
        
    elif backup_code == 'SCHEMA':
        
        print global_parameters['backup_server_pgsql_bin_dir'] + '/pg_dump' + \
            ' -h ' + pgsql_node + \
            ' -p ' + pgsql_node_port + \
            ' -U ' + pgsql_node_admin_user + \
            ' --file=' +  global_parameters['database_dump_file'] + \
            ' --format=c' + \
            ' --schema-only' + \
            ' ' + extra_parameters + \
            ' ' + dbname + \
            ' > ' + global_parameters['database_log_file'] + ' 2>&1' 
        
    elif backup_code == 'DATA':
        
        print global_parameters['backup_server_pgsql_bin_dir'] + '/pg_dump' + \
            ' -h ' + pgsql_node + \
            ' -p ' + pgsql_node_port + \
            ' -U ' + pgsql_node_admin_user + \
            ' --file=' + global_parameters['database_dump_file'] + \
            ' --format=c' + \
            ' --data-only' + \
            ' ' + extra_parameters + \
            ' ' + dbname + \
            ' > ' +  global_parameters['database_log_file']+ ' 2>&1' 
        


# ############################################
# Function 
# ############################################
    
def pg_dump_users(global_parameters):
    '''pg_dump_users function'''
    
    roles = []

    #
    # We need a list with all the roles that own an object in the database we are
    # taking a backup for. We do this in this way:
    #
    # - We generate a temp file with a schema dump of the database
    # - We extract all the roles used in sql statements that use OWNER TO
    # - We extract all roles used in sql statements GRANT .... TO
    # - We generate a temp file with a pg_dumpall -r dump of the cluster running our database
    # - We extract all the lines from the second temp file that have information about some
    #   of the roles extracted from the first temp file
    #
    # We do all this process via temp files insteed of piping the outputs from process to process
    # to avoid problems with huge sql dumps
    #

    # 
    # Extracting roles from the schema dump of the database
    #

    try:
        pg_dump_schema_temp_file = tempfile.NamedTemporaryFile(delete=True,dir=global_parameters['tmp_dir'])
        logs.logger.debug('pg_dump schema temp file created %s',pg_dump_schema_temp_file.name)
    
        try:
            proc = subprocess.Popen([global_parameters['backup_server_pgsql_bin_dir'] + "/pg_dump", \
                                         "-h",pgsql_node, \
                                         "-p",pgsql_node_port, \
                                         "-U",pgsql_node_admin_user, \
                                         "-s",dbname], \
                                        stdout=pg_dump_schema_temp_file, \
                                        stderr=subprocess.STDOUT)
            proc.wait()

            if proc.returncode != 0:
                logs.logger.critical('The command used to generate the tmp schema dump of the database %s has a return value != 0',dbname)
                sys.exit(1)
                
            with open(pg_dump_schema_temp_file.name, 'r') as sqldump:
                for line in sqldump:
                     if 'OWNER TO' in line:
                         role = line.split(' OWNER TO ')[1].replace(';\n','')
                         roles.append(role)
                                             
                     if 'GRANT' in line:
                         role = line.split(' TO ')[1].replace(';\n','')
                         
                         if role != 'PUBLIC':
                             roles.append(role)
                             
                unique_role_list = set(roles)
                
            logs.logger.debug('The list of roles we need to restore the database %s has been generated - %s',dbname,unique_role_list)
            pg_dump_schema_temp_file.close()
            
        except OSError as e:
            logs.logger.critical('Could not generate the tmp schema dump of the database %s - %s',dbname,e)
            sys.exit(1)
        
    except OSError as e:
        logs.logger.critical('pg_dump schema temp file could not be created in directory %s - %s',global_parameters['tmp_dir'],e)
        sys.exit(1)
  
    #
    # Extracting sql statements for our roles from the pg_dumpall -r dump of the cluster
    # 
    
    try:
        pg_dumpall_roles_temp_file = tempfile.NamedTemporaryFile(delete=True,dir=global_parameters['tmp_dir'])
        logs.logger.debug('pg_dumpall roles temp file created %s',pg_dumpall_roles_temp_file.name)
    
        try:
            proc = subprocess.Popen([global_parameters['backup_server_pgsql_bin_dir'] + "/pg_dumpall", \
                                         "-r", \
                                         "-h",pgsql_node, \
                                         "-p",pgsql_node_port, \
                                         "-U",pgsql_node_admin_user], \
                                        stdout=pg_dumpall_roles_temp_file, \
                                        stderr=subprocess.STDOUT)
            proc.wait()

            if proc.returncode != 0:
                logs.logger.critical('The command used to generate the role dump for the PgSQL node running the database %s has a return value != 0',dbname)
                sys.exit(1)
                
            with open(pg_dumpall_roles_temp_file.name, 'r') as sqldump_roles:
                for line in sqldump_roles:
                    for role in unique_role_list:

                        #
                        # CREATE ROLE statements
                        #
                        if ' ROLE ' + role + ';' in line:
                            print line.replace('\n','')
                        
                        #
                        # ALTER ROLE statements
                        #
                        if ' ROLE ' + role + ' ' in line:
                            print line.replace('\n','')

            logs.logger.debug('The list of role statements we need from pg_dumpall has been generated')
            pg_dumpall_roles_temp_file.close()
            
        except OSError as e:
            logs.logger.critical('Could not generate the tmp role dump of the cluster running the database %s - %s',dbname,e)
            sys.exit(1)
        
    except OSError as e:
        logs.logger.critical('pg_dumpall role temp file could not be created in directory %s - %s',global_parameters['tmp_dir'],e)
        sys.exit(1)



# ############################################
# Function 
# ############################################
    
def pg_dump_database_config(global_parameters):
    '''pg_dump_database_config function'''



# ############################################
# Function handler
# ############################################
    
def get_pgsql_node_dsn(global_parameters,db):
    '''Get the DSN values for a pgsql_node'''

    dsn_value = db.get_pgsql_node_dsn(global_parameters['pgsql_node_id'])

    if dsn_value != None:
        logs.logger.debug('DSN value for PgSQL node %s is %s',pgsql_node,dsn_value)
        return dsn_value
    else:
        logs.logger.critical('PgSQL node: %s is not registered in PgBackMan',pgsql_node)
        sys.exit(1)


# ############################################
# Function handler
# ############################################
    
def get_pgsql_node_release(db):
    '''Get the release pgsql_node is running'''

    pgsql_node_version = str(db.get_server_version())[0:4]
        
    if pgsql_node_version == '9030':
        pgsql_node_release = '9.3'
    elif pgsql_node_version == '9020':
        pgsql_node_release = '9.2'
    elif pgsql_node_version == '9010':
        pgsql_node_release = '9.1'
    elif pgsql_node_version == '9000':
        pgsql_node_release = '9.0'
    elif pgsql_node_version == '8040':
        pgsql_node_release = '8.4'
    else:
        pgsql_node_release = None

    if  pgsql_node_release != None:
        logs.logger.debug('PgSQL node %s is running postgreSQL %s',pgsql_node,pgsql_node_release)
        return pgsql_node_release
    else:
        logs.logger.critical('Could not get the postgreSQL release for this PgSQL node: %s',pgsql_node)
        sys.exit(1)
    
    
# ############################################
# Function handler
# ############################################
    
def get_backup_server_pgsql_bin_dir(global_parameters,db):
    '''Get the directory with postgreSQL binaries to use'''

    pgsql_bin_dir = db.get_backup_server_parameter(global_parameters['backup_server_id'],'pgsql_bin_' + global_parameters['pgsql_node_release'])
    
    if pgsql_bin_dir != None:
        logs.logger.debug('pgsql bin directory to use: %s',pgsql_bin_dir)
        return pgsql_bin_dir
    else:
        logs.logger.critical('Could not get the pgsql bin directory for this PgSQL node: %s',pgsql_node)
        sys.exit(1)


# ############################################
# Function handler
# ############################################
    
def get_filename_id(global_parameters,dump_type,file_type):
    '''Generate the filename used for the backup and log files of a backup job'''
    
    timestamp = datetime.datetime.now().strftime('%Y%m%dT%H%M%S')
    filename_id = global_parameters['pgsql_node_backup_dir'] + '/' + file_type + '/' + dbname + '-' + pgsql_node + '-v' + global_parameters['pgsql_node_release'] + '-j' + backup_job_id + '-' + dump_type + '-c' + backup_code + '-fcustom-' + timestamp 

    return filename_id


# ############################################
# Function handler
# ############################################
    
def check_pgsql_node_backup_directories(global_parameters,db):
    '''
    Check if the directories needed by pgbackman for a PgSQL node are in place
    If they do not exist, we try to create them.
    '''
    if  global_parameters['pgsql_node_backup_dir'] != None:
        logs.logger.debug('PgSQL node backup partition to use: %s',global_parameters['pgsql_node_backup_dir'])
        
        if os.path.exists(global_parameters['pgsql_node_backup_dir'] + '/dump'):
            logs.logger.debug('Dump directory %s exists',global_parameters['pgsql_node_backup_dir'] + '/dump')
        else:
            logs.logger.error('Dump directory %s does not exist',global_parameters['pgsql_node_backup_dir'] + '/dump')
            
            try:
                os.makedirs(global_parameters['pgsql_node_backup_dir'] + '/dump',0700)
                logs.logger.info('Dump directory %s created',global_parameters['pgsql_node_backup_dir'] + '/dump')
            except OSError as e:
                logs.logger.critical('OS error when creating the dump directory: %s',e)
                sys.exit(1)
                
        if os.path.exists(global_parameters['pgsql_node_backup_dir'] + '/log'):
            logs.logger.debug('Log directory %s exists',global_parameters['pgsql_node_backup_dir'] + '/log')
        else:
            logs.logger.error('Log directory %s does not exist',global_parameters['pgsql_node_backup_dir'] + '/log')
            
            try:
                os.makedirs(global_parameters['pgsql_node_backup_dir'] + '/log',0700)
                logs.logger.info('Log directory %s created',global_parameters['pgsql_node_backup_dir'] + '/log')
            except OSError as e:
                logs.logger.critical('OS error when creating the log directory: %s',e)
                sys.exit(1)       

    else:
        logs.logger.critical('Could not get the PgSQL node backup partition for: %s',pgsql_node)
        sys.exit(1)


# ############################################
# Function handler
# ############################################
    
def signal_handler(signum, frame):
    logs.logger.info('**** pgbackman_dump stopped. ****')
    sys.exit(0)


# ############################################
# Function 
# ############################################
    
def main():
    '''Main function'''
    
    global_parameters = {}

    conf = configuration()
    pgbackman_dsn = conf.dsn
    global_parameters['tmp_dir'] = conf.tmp_dir

    db = pgbackman_db(pgbackman_dsn,logs,'pgbackman_dump')

    global_parameters['pgsql_node_id'] = db.get_pgsql_node_id(pgsql_node)
    
    pgsql_node_dsn = get_pgsql_node_dsn(global_parameters,db)
    db_pgnode = pgbackman_db(pgsql_node_dsn,logs,'pgbackman_dump')

    # 
    # The backup server FQDN to be used can be defined in the pgbackman configuration file.
    # If the configuration parameter 'backup_server' is not defined, the return value of  
    # socket.getfqdn() will be used.
    #
    # The FQDN of the backup server will be used to find out the internal pgbackman ID of the backup 
    # server
    #

    if conf.backup_server != '':
        backup_server_id = db.get_backup_server_id(conf.backup_server)
        
        if backup_server_id == False:
            logs.logger.critical('Backup server %s does not exist in pgbackman. Stopping pgbackman2cron.',conf.backup_server)
            logs.logger.info('**** pgbackman_dump stopped. ****')
            sys.exit()     
        else:
            logs.logger.debug('Backup server: %s up and running',conf.backup_server)
    else:
        backup_server_id = db.get_backup_server_id(socket.getfqdn())

        if backup_server_id == False:
            logs.logger.critical('Backup server %s does not exist in pgbackman. Stopping pgbackman2cron.',socket.getfqdn())
            logs.logger.info('**** pgbackman_dump stopped. ****')
            sys.exit()     
        else:
            logs.logger.debug('Backup server: %s up and running',socket.getfqdn())

    global_parameters['backup_server_id'] = backup_server_id
 
    global_parameters['pgsql_node_backup_dir'] = db.get_pgsql_node_parameter(global_parameters['pgsql_node_id'],'pgnode_backup_partition')
    global_parameters['pgsql_node_release'] = get_pgsql_node_release(db_pgnode)
    global_parameters['backup_server_pgsql_bin_dir'] = get_backup_server_pgsql_bin_dir(global_parameters,db)
    
    global_parameters['database_dump_file'] = get_filename_id(global_parameters,'DATABASE','dump') + '.sql'
    global_parameters['database_log_file'] = get_filename_id(global_parameters,'DATABASE','log') + '.log'

    global_parameters['users_dump_file'] = get_filename_id(global_parameters,'USERS','dump') + '.sql'
    global_parameters['users_log_file'] = get_filename_id(global_parameters,'USERS','log') + '.log'
 
    global_parameters['dbconfig_dump_file'] = get_filename_id(global_parameters,'DBCONFIG','dump') + '.sql'
    global_parameters['dbconfig_log_file'] = get_filename_id(global_parameters,'DBCONFIG','log') + '.log'
       
    check_pgsql_node_backup_directories(global_parameters,db)
    pg_dump(global_parameters)
    pg_dump_users(global_parameters)


# ############################################
# 
# ############################################

if __name__ == '__main__':

    logs = logs("pgbackman_dump")

    signal.signal(signal.SIGINT,signal_handler)
    signal.signal(signal.SIGTERM,signal_handler)

    parser = argparse.ArgumentParser(prog=sys.argv[0])
    parser.add_argument('-H', metavar='PGSQL-NODE', required=True, help='PgSQL node FQDN', dest='pgsql_node')
    parser.add_argument('-p', metavar='PGSQL-NODE-PORT', required=True, help='PgSQL node port', dest='pgsql_node_port')
    parser.add_argument('-U', metavar='PGSQL-NODE_ADMIN-USER', required=True, help='PgSQL node admin user', dest='pgsql_node_admin_user')
    parser.add_argument('-j', metavar='JOBID', required=True, help='Backup job ID', dest='backup_job_id')
    parser.add_argument('-d', metavar='DBNAME', required=True, help='Database name', dest='dbname')
    parser.add_argument('-c', metavar='[FULL|SCHEMA|DATA]', choices=['FULL', 'SCHEMA', 'DATA'], required=True, help='Backup code', dest='backup_code')
    parser.add_argument('-e', metavar='[FALSE|TRUE]', default=False, required=True, help='Activate encryption', dest='encryption')
    parser.add_argument('-P', metavar='EXTRA-PARAMETERS', required=False, help='extra pg_dump parameters', dest='extra_parameters')

    args = parser.parse_args()    
    print args

    logs.logger.info('**** pgbackman_dump started. ****')
    
    if args.pgsql_node:
        pgsql_node = args.pgsql_node
    else:
        logs.logger.error('PgSQL node parameter not defined')
        sys.exit(1)

    if args.pgsql_node_port:
        pgsql_node_port = args.pgsql_node_port
    else:
        logs.logger.error('PgSQL node port parameter not defined')
        sys.exit(1)
    
    if args.pgsql_node_admin_user:
        pgsql_node_admin_user = args.pgsql_node_admin_user
    else:
        logs.logger.error('PgSQL node admin user parameter not defined')
        sys.exit(1)
    
    if args.backup_job_id:
        backup_job_id = args.backup_job_id
    else:
        logs.logger.error('Backup jobID parameter not defined')
        sys.exit(1)

    if args.dbname:
        dbname = args.dbname
    else:
        logs.logger.error('DBname parameter not defined')
        sys.exit(1)

    if args.encryption:
        encryption = args.encryption
    else:
        logs.logger.error('Encryption parameter not defined')
        sys.exit(1)
        
    if args.backup_code:
        backup_code = args.backup_code
    else:
        logs.logger.error('Backup code parameter not defined')
        sys.exit(1)

    if args.extra_parameters:
        extra_parameteres = args.extra_parameteres
    else:
        extra_parameters = ''

    main()
